<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Weikang Wang</title>
  
  <meta name="author" content="Weikang Wang">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/png" href="images/seal_icon.png">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Weikang Wang</name>
              </p>
              <p>I am now an academic visiting student at <a href="http://en.cs.ustc.edu.cn/">Department of Computer Science and Technology</a>
                of <a href="http://en.ustc.edu.cn/">University of Science and Technology of China</a>,
                supervised by <a href="http://staff.ustc.edu.cn/~sfwang/">Prof. Wang S. F.</a> and <a href="http://staff.ustc.edu.cn/~cheneh/">Prof. Chen E. H.</a>, 
                concentrating on computer vision and machine learning.
              </p>
              <p>
                I completed my Master of Science degree in <a href="https://www.ee.columbia.edu/">Electrical Engineering</a> of <a href="https://www.columbia.edu/">Columbia University</a>, 
                where I have been lucky worked with <a href="https://www.ee.columbia.edu/john-wright">Prof. John Wright</a>, 
                <a href="https://www.ee.columbia.edu/chong-li">Prof. Li C.</a> and <a href="https://www.ee.columbia.edu/zoran-kostic">Prof. Zoran Kostic</a>.
                Before that, I got my Bachelor of Engineering degree in Automation with distiction from <a href="https://ev.buaa.edu.cn/">Beihang University</a>, 
                supervised by <a href="http://shi.buaa.edu.cn/mpl/en/index.htm">Prof. Zhang B. C.</a>.
              </p>
              <p style="text-align:center">
                <a href="mailto:wkwang0916@outlook.com">Email</a> &nbsp/&nbsp
                <a href="data/weikangwang_CV.pdf">CV</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?user=-Q4I3V4AAAAJ&hl=en">Google Scholar</a> &nbsp/&nbsp
                <a href="https://github.com/Wei-kang-Wang">Github</a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/weikangwang.jpg"><img style="width:100%;max-width:100%" alt="profile photo" src="images/weikangwang.jpg" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
        
         <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>News</heading>
              <p>
                <li>I'm now looking for PhD position with wide interests including machine learning, computer vision, image processing and statistical learning theory.
              </p>
              <p>
                <li><b>07/2020:</b>Our paper <a href="https://dl.acm.org/doi/abs/10.1145/3394171.3413774">Learning from Macro expressions: A Micro-expression Recognition Framework</a> 
                 has been accepted by ACM Multimedia 2020.
              </p>
              <p>
                <li><b>03/2020:</b>I got my PhD offers of Electrical and Computer Engineering from Texas A&M University with <span style="color:red">Fully Scholarships</span>. But I 
             <b>DECLINED</b> due to visa issue problem.
              </p>
              <p>
                <li><b>04/2020</b>:I got my PhD offers of Electrical and Computer Engineering from University of Virginia with <span style="color:red">Fully Scholarships</span>. But I 
               <b>DECLINED</b> due to visa issue problem.
            </p>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Research</heading>
              <p>
                I'm interested in computer vision, machine learning, statistical learning theory, and image processing.
              </p>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

          <tr onmouseout="dualrefl_stop()" onmouseover="dualrefl_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='dualrefl_image'>
                  <img src='images/dualrefl_after.jpg' width="160"></div>
                <img src='images/dualrefl_before.jpg' width="160">
              </div>
              <script type="text/javascript">
                function dualrefl_start() {
                  document.getElementById('dualrefl_image').style.opacity = "1";
                }

                function dualrefl_stop() {
                  document.getElementById('dualrefl_image').style.opacity = "0";
                }
                dualrefl_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="http://sniklaus.com/dualref">
                <papertitle>Learned Dual-View Reflection Removal</papertitle>
              </a>
              <br>
              <a href="http://sniklaus.com/welcome">Simon Niklaus</a>,
              <a href="https://people.eecs.berkeley.edu/~cecilia77/">Xuaner (Cecilia) Zhang</a>,
              <strong>Jonathan T. Barron</strong>,
              <a href="http://nealwadhwa.com">Neal Wadhwa</a>,
              <a href="http://rahuldotgarg.appspot.com/">Rahul Garg</a>,
              <a href="http://web.cecs.pdx.edu/~fliu/">Feng Liu</a>,
              <a href="https://people.csail.mit.edu/tfxue/">Tianfan Xue</a>,
              <br>
              <em>arXiv</em>, 2020  
              <br>
              <a href="http://sniklaus.com/dualref">project page</a> /
              <a href="https://arxiv.org/abs/2010.00702">arXiv</a>
              <p></p>
              <p>
                Reflections and the things behind them often exhibit parallax, and this lets you remove reflections from stereo pairs.
              </p>
            </td>
          </tr> 

          <tr onmouseout="nlt_stop()" onmouseover="nlt_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='nlt_image'><video  width=100% height=100% muted autoplay loop>
                <source src="images/nlt_after.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
                <img src='images/nlt_before.jpg' width="160">
              </div>
              <script type="text/javascript">
                function nlt_start() {
                  document.getElementById('nlt_image').style.opacity = "1";
                }

                function nlt_stop() {
                  document.getElementById('nlt_image').style.opacity = "0";
                }
                nlt_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="http://nlt.csail.mit.edu/">
                <papertitle>Neural Light Transport for Relighting and View Synthesis</papertitle>
              </a>
              <br>
              <a href="http://people.csail.mit.edu/xiuming/">Xiuming Zhang</a>,
              <a href="http://www.seanfanello.it/">Sean Fanello</a>,
              <a href="https://research.google/people/105312/">Yun-Ta Tsai</a>,
              <a href="http://kevinkingo.com/">Tiancheng Sun</a>,
              <a href="https://people.csail.mit.edu/tfxue/">Tianfan Xue</a>,
              <a href="https://research.google/people/106687/">Rohit Pandey</a>,
              <a href="https://www.dtic.ua.es/~sorts/">Sergio Orts-Escolano</a>,
              <a href="https://dl.acm.org/profile/99659224296">Philip Davidson</a>,
              <a href="https://scholar.google.com/citations?user=5D0_pjcAAAAJ&hl=en">Christoph Rhemann</a>,
              <a href="http://www.pauldebevec.com/">Paul Debevec</a>,
              <strong>Jonathan T. Barron</strong>,
              <a href="http://cseweb.ucsd.edu/~ravir/">Ravi Ramamoorthi</a>,
              <a href="http://billf.mit.edu/">William T. Freeman</a>
              <br>
              <em>arXiv</em>, 2020  
              <br>
              <a href="http://nlt.csail.mit.edu/">project page</a> /
              <a href="https://arxiv.org/abs/2008.03806">arXiv</a> /
              <a href="https://www.youtube.com/watch?v=OGEnCWZihHE">video</a>
              <p></p>
              <p>Embedding a convnet within a predefined texture atlas enables simultaneous view synthesis and relighting.</p>
            </td>
          </tr> 

          <tr onmouseout="nerfw_stop()" onmouseover="nerfw_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='nerfw_image'><video  width=100% height=100% muted autoplay loop>
                <source src="images/nerfw_after.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
                <img src='images/nerfw_before.jpg' width="160">
              </div>
              <script type="text/javascript">
                function nerfw_start() {
                  document.getElementById('nerfw_image').style.opacity = "1";
                }

                function nerfw_stop() {
                  document.getElementById('nerfw_image').style.opacity = "0";
                }
                nerfw_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://nerf-w.github.io/">
                <papertitle>NeRF in the Wild: Neural Radiance Fields for Unconstrained Photo Collections</papertitle>
              </a>
              <br>
              <a href="http://www.ricardomartinbrualla.com/">Ricardo Martin-Brualla*</a>,
              <a href="https://scholar.google.com/citations?user=g98QcZUAAAAJ&hl=en">Noha Radwan*</a>,
              <a href="https://research.google/people/105804/">Mehdi S. M. Sajjadi*</a>,
              <strong>Jonathan T. Barron</strong>,
              <a href="https://scholar.google.com/citations?user=FXNJRDoAAAAJ&hl=en">Alexey Dosovitskiy</a>,
              <a href="http://www.stronglyconvex.com/about.html">Daniel Duckworth</a>
              <br>
              <em>arXiv</em>, 2020  
              <br>
              <a href="https://nerf-w.github.io/">project page</a> /
              <a href="https://arxiv.org/abs/2008.02268">arXiv</a> /
              <a href="https://www.youtube.com/watch?v=yPKIxoN2Vf0">video</a>
              <p></p>
              <p>Letting NeRF reason about occluders and appearance variation produces photorealistic view synthesis using only unstructured internet photos.</p>
            </td>
          </tr> 

          <tr onmouseout="ff_stop()" onmouseover="ff_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='ff_image'>
                  <img src='images/lion_ff.jpg' width="160"></div>
                <img src='images/lion_none.jpg' width="160">
              </div>
              <script type="text/javascript">
                function ff_start() {
                  document.getElementById('ff_image').style.opacity = "1";
                }

                function ff_stop() {
                  document.getElementById('ff_image').style.opacity = "0";
                }
                ff_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://people.eecs.berkeley.edu/~bmild/fourfeat/index.html">
                <papertitle>Fourier Features Let Networks Learn High Frequency Functions in Low Dimensional Domains</papertitle>
              </a>
              <br>
              <a href="http://matthewtancik.com/">Matthew Tancik*</a>,
              <a href="https://people.eecs.berkeley.edu/~pratul/">Pratul Srinivasan*</a>,
              <a href="https://people.eecs.berkeley.edu/~bmild/">Ben Mildenhall*</a>,
              <a href="https://people.eecs.berkeley.edu/~sfk/">Sara Fridovich-Keil</a>,
              <a href="https://www.linkedin.com/in/nithinraghavan">Nithin Raghavan</a>,
              <a href="https://scholar.google.com/citations?user=lvA86MYAAAAJ&hl=en">Utkarsh Singhal</a>,
              <a href="http://cseweb.ucsd.edu/~ravir/">Ravi Ramamoorthi</a>,
              <strong>Jonathan T. Barron</strong>,
              <a href="https://www2.eecs.berkeley.edu/Faculty/Homepages/yirenng.html">Ren Ng</a>
              <br>
              <em>NeurIPS</em>, 2020 &nbsp <font color=#FF8080><strong>(Spotlight)</strong></font>
              <br>
              <a href="https://people.eecs.berkeley.edu/~bmild/fourfeat/">project page</a> /
              video: <a href="https://www.youtube.com/watch?v=nVA6K6Sn2S4">3 min</a>, <a href="TODO">10 min</a> /
              <a href="https://arxiv.org/abs/2006.10739">arXiv</a> /
              <a href="https://github.com/tancik/fourier-feature-networks">code</a>
              <p></p>
              <p>Composing neural networks with a simple Fourier feature mapping allows them to learn detailed high-frequency functions.</p>
            </td>
          </tr> 

    
          <tr onmouseout="thresh_stop()" onmouseover="thresh_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='thresh_image'>
                  <img src='images/thresh_after.png' width="160"></div>
                <img src='images/thresh_before.jpg' width="160">
              </div>
              <script type="text/javascript">
                function thresh_start() {
                  document.getElementById('thresh_image').style.opacity = "1";
                }

                function thresh_stop() {
                  document.getElementById('thresh_image').style.opacity = "0";
                }
                thresh_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/abs/2007.07350">
                <papertitle>A Generalization of Otsu's Method and Minimum Error Thresholding</papertitle>
              </a>
              <br>
              <strong>Jonathan T. Barron</strong>
              <br>
              <em>ECCV</em>, 2020 &nbsp <font color=#FF8080><strong>(Spotlight)</strong></font>
              <br>
              <a href="https://github.com/jonbarron/hist_thresh">code</a> / 
              <a href="https://www.youtube.com/watch?v=rHtQQlQo1Q4">video</a> / 
              <a href="data/BarronECCV2020.bib">bibtex</a>
              <br>
              <p></p>
              <p>
              A simple and fast Bayesian algorithm that can be written in ~10 lines of code outperforms or matches giant CNNs on image binarization, and unifies three classic thresholding algorithms.
              </p>
            </td>
          </tr>  
    
    
          <tr onmouseout="uflow_stop()" onmouseover="uflow_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='uflow_image'>
                  <img src='images/uflow_after.png' width="160"></div>
                <img src='images/uflow_before.jpg' width="160">
              </div>
              <script type="text/javascript">
                function uflow_start() {
                  document.getElementById('uflow_image').style.opacity = "1";
                }

                function uflow_stop() {
                  document.getElementById('uflow_image').style.opacity = "0";
                }
                uflow_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/abs/2006.04902">
                <papertitle>What Matters in Unsupervised Optical Flow</papertitle>
              </a>
              <br>
              <a href="http://ricojonschkowski.com/">Rico Jonschkowski</a>,
              <a href="https://www.linkedin.com/in/austin-charles-stone-1ba33b138/">Austin Stone</a>,
              <strong>Jonathan T. Barron</strong>,
              <a href="https://research.google/people/ArielGordon/">Ariel Gordon</a>,
              <a href="https://www.linkedin.com/in/kurt-konolige/">Kurt Konolige</a>,
              <a href="https://research.google/people/AneliaAngelova/">Anelia Angelova</a>
              <br>
              <em>ECCV</em>, 2020 &nbsp <font color="red"><strong>(Oral Presentation)</strong></font>
              <br>
              <a href="https://github.com/google-research/google-research/tree/master/uflow">code</a>
              <br>
              <p></p>
              <p>
              Extensive experimentation yields a simple optical flow technique that is trained on only unlabeled videos, but still works as well as supervised techniques.
              </p>
            </td>
          </tr>  
    
          <tr onmouseout="nerf_stop()" onmouseover="nerf_start()"  bgcolor="#ffffd0">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='nerf_image'><video  width=100% height=100% muted autoplay loop>
                <source src="images/vase_small.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
                <img src='images/vase_still.png' width="160">
              </div>
              <script type="text/javascript">
                function nerf_start() {
                  document.getElementById('nerf_image').style.opacity = "1";
                }

                function nerf_stop() {
                  document.getElementById('nerf_image').style.opacity = "0";
                }
                nerf_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="http://www.matthewtancik.com/nerf">
                <papertitle>NeRF: Representing Scenes as Neural Radiance Fields for View Synthesis</papertitle>
              </a>
              <br>
              <a href="https://people.eecs.berkeley.edu/~bmild/">Ben Mildenhall*</a>,
              <a href="https://people.eecs.berkeley.edu/~pratul/">Pratul Srinivasan*</a>,
              <a href="http://matthewtancik.com/">Matthew Tancik*</a>,
              <strong>Jonathan T. Barron</strong>,
              <a href="http://cseweb.ucsd.edu/~ravir/">Ravi Ramamoorthi</a>,
              <a href="https://www2.eecs.berkeley.edu/Faculty/Homepages/yirenng.html">Ren Ng</a>
              <br>
              <em>ECCV</em>, 2020 &nbsp <font color="red"><strong>(Oral Presentation, Best Paper Honorable Mention)</strong></font>
              <br>
              <a href="http://www.matthewtancik.com/nerf">project page</a>
              /
              <a href="https://arxiv.org/abs/2003.08934">arXiv</a>
              /
              <a href="https://www.youtube.com/watch?v=LRAqeM8EjOo&t">talk video</a>
              /
              <a href="https://www.youtube.com/watch?v=JuH79E8rdKc">supp video</a>
              /
              <a href="https://github.com/bmild/nerf">code</a>
              <p></p>
              <p>
              Training a tiny non-convolutional neural network to reproduce a scene using volume rendering achieves photorealistic view synthesis.</p>
            </td>
          </tr> 

          <tr onmouseout="porshadmanip_stop()" onmouseover="porshadmanip_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='porshadmanip_image'>
                  <img src='images/porshadmanip_after.jpg' width="160"></div>
                <img src='images/porshadmanip_before.jpg' width="160">
              </div>
              <script type="text/javascript">
                function porshadmanip_start() {
                  document.getElementById('porshadmanip_image').style.opacity = "1";
                }

                function porshadmanip_stop() {
                  document.getElementById('porshadmanip_image').style.opacity = "0";
                }
                porshadmanip_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/abs/2005.08925">
                <papertitle>Portrait Shadow Manipulation</papertitle>
              </a>
              <br>
              <a href="https://people.eecs.berkeley.edu/~cecilia77/">Xuaner (Cecilia) Zhang</a>,
              <strong>Jonathan T. Barron</strong>,
              <a href="https://ai.google/research/people/105312/">Yun-Ta Tsai</a>,
              <a href="https://www.linkedin.com/in/rohit-pandey-bab10b7a/">Rohit Pandey</a>,
              <a href="http://people.csail.mit.edu/xiuming/">Xiuming Zhang</a>,
              <a href="http://graphics.stanford.edu/~renng/">Ren Ng</a>,
              <a href="http://graphics.stanford.edu/~dejacobs/">David E. Jacobs</a>
              <br>
              <em>SIGGRAPH</em>, 2020  
              <br>
              <a href="https://people.eecs.berkeley.edu/~cecilia77/project-pages/portrait">project page</a> / 
              <a href="https://www.youtube.com/watch?v=M_qYTXhzyac">video</a>
              <p></p>
              <p>Networks can be trained to remove shadows cast on human faces and to soften harsh lighting.</p>
            </td>
          </tr>  

          <tr onmouseout="learnaf_stop()" onmouseover="learnaf_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='learnaf_image'>
                  <img src='images/learnaf_after.jpg' width="160"></div>
                <img src='images/learnaf_before.jpg' width="160">
              </div>
              <script type="text/javascript">
                function learnaf_start() {
                  document.getElementById('learnaf_image').style.opacity = "1";
                }

                function learnaf_stop() {
                  document.getElementById('learnaf_image').style.opacity = "0";
                }
                learnaf_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/abs/2004.12260">
                <papertitle>Learning to Autofocus</papertitle>
              </a>
              <br>
              <a href="">Charles Herrmann</a>,
              <a href="">Richard Strong Bowen</a>,
              <a href="http://nealwadhwa.com">Neal Wadhwa</a>,
              <a href="http://rahuldotgarg.appspot.com/">Rahul Garg</a>,
              <a href="https://scholar.google.com/citations?user=BxqV_RsAAAAJ">Qiurui He</a>,
              <strong>Jonathan T. Barron</strong>,
              <a href="http://www.cs.cornell.edu/~rdz/index.htm">Ramin Zabih</a>
              <br>
              <em>CVPR</em>, 2020  
              <br>
              <a href="https://arxiv.org/abs/2004.12260">arXiv</a>
              <p></p>
              <p>Machine learning can be used to train cameras to autofocus (which is not the same problem as "depth from defocus").</p>
            </td>
          </tr>  

    
          <tr onmouseout="lighthouse_stop()" onmouseover="lighthouse_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='lh_image'><video width=100% height=100% muted autoplay loop>
                <source src="images/rings_crop.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
                <img src='images/rings.png' width="160">
              </div>
              <script type="text/javascript">
                function lighthouse_start() {
                  document.getElementById('lh_image').style.opacity = "1";
                }

                function lighthouse_stop() {
                  document.getElementById('lh_image').style.opacity = "0";
                }
                lighthouse_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://people.eecs.berkeley.edu/~pratul/lighthouse/">
                <papertitle>Lighthouse: Predicting Lighting Volumes for Spatially-Coherent Illumination</papertitle>
              </a>
              <br>
              <a href="https://people.eecs.berkeley.edu/~pratul/">Pratul Srinivasan*</a>,
              <a href="https://people.eecs.berkeley.edu/~bmild/">Ben Mildenhall*</a>,
              <a href="http://matthewtancik.com/">Matthew Tancik</a>,
              <strong>Jonathan T. Barron</strong>,
              <a href="https://research.google/people/RichardTucker/">Richard Tucker</a>,
              <a href="https://www.cs.cornell.edu/~snavely/">Noah Snavely</a>
              <br>
        <em>CVPR</em>, 2020  
              <br>
              <a href="https://people.eecs.berkeley.edu/~pratul/lighthouse/">project page</a>
        /
              <a href="https://github.com/pratulsrinivasan/lighthouse">code</a>
        /
              <a href="https://arxiv.org/abs/2003.08367">arXiv</a>
        /
              <a href="https://www.youtube.com/watch?v=KsiZpUFPqIU">video</a>
              <p></p>
              <p>We predict a volume from an input stereo pair that can be used to calculate incident lighting at any 3D point within a scene.</p>
            </td>
          </tr>  

          <tr onmouseout="skyopt_stop()" onmouseover="skyopt_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='skyopt_image'>
                  <img src='images/skyopt_after.jpg' width="160"></div>
                <img src='images/skyopt_before.jpg' width="160">
              </div>
              <script type="text/javascript">
                function skyopt_start() {
                  document.getElementById('skyopt_image').style.opacity = "1";
                }

                function skyopt_stop() {
                  document.getElementById('skyopt_image').style.opacity = "0";
                }
                skyopt_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/abs/2006.10172">
                <papertitle>Sky Optimization: Semantically Aware Image Processing of Skies in Low-Light Photography</papertitle>
              </a>
              <br>
              <a href="https://sites.google.com/corp/view/orly-liba/">Orly Liba</a>,
              <a href="https://www.linkedin.com/in/longqicai/en-us">Longqi Cai</a>,
              <a href="https://ai.google/research/people/105312/">Yun-Ta Tsai</a>,
              <a href="https://research.google/people/EladEban/">Elad Eban</a>,
              <a href="https://research.google/people/YairMovshovitzAttias/">Yair Movshovitz-Attias</a>,
              <a href="https://scholar.google.com/citations?user=2jXxOYQAAAAJ">Yael Pritch</a>,
              <a href="https://www.linkedin.com/in/huizhong-chen-00776432">Huizhong Chen</a>,
              <strong>Jonathan T. Barron</strong>
              <br>
              <em>NTIRE CVPRW</em>, 2020  
              <br>
              <a href="https://google.github.io/sky-optimization/">project page</a>
              <p></p>
              <p>If you want to photograph the sky, it helps to know where the sky is.</p>
            </td>
          </tr>  

          <tr onmouseout="nightsight_stop()" onmouseover="nightsight_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='nightsight_image'><img src='images/nightsight_after.jpg'></div>
                <img src='images/nightsight_before.jpg'>
              </div>
              <script type="text/javascript">
                function nightsight_start() {
                  document.getElementById('nightsight_image').style.opacity = "1";
                }

                function nightsight_stop() {
                  document.getElementById('nightsight_image').style.opacity = "0";
                }
                nightsight_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/abs/1910.11336">
                <papertitle>Handheld Mobile Photography in Very Low Light</papertitle>
              </a>
              <br>
              <a href="https://sites.google.com/site/orlylibaprofessional/">Orly Liba</a>,
              <a href="https://scholar.google.com/citations?user=6PhlPWMAAAAJ">Kiran Murthy</a>,
              <a href="https://ai.google/research/people/105312/">Yun-Ta Tsai</a>,
              <a href="https://www.timothybrooks.com/">Timothy Brooks</a>,
              <a href="https://people.csail.mit.edu/tfxue/">Tianfan Xue</a>,
              <a href="https://scholar.google.com/citations?user=qgc_jY0AAAAJ">Nikhil Karnad</a>,
              <a href="https://scholar.google.com/citations?user=BxqV_RsAAAAJ">Qiurui He</a>,
              <strong>Jonathan T. Barron</strong>,
              <a href="https://ai.google/research/people/105641/">Dillon Sharlet</a>,
              <a href="http://www.geisswerks.com/">Ryan Geiss</a>,
              <a href="https://people.csail.mit.edu/hasinoff/">Samuel W. Hasinoff</a>,
              <a href="https://scholar.google.com/citations?user=2jXxOYQAAAAJ">Yael Pritch</a>,
              <a href="http://graphics.stanford.edu/~levoy/">Marc Levoy</a>
              <br>
              <em>SIGGRAPH Asia</em>, 2019
              <br>
              <a href="https://github.com/google/night-sight/tree/master/docs">project page</a>
              <br>
              <p></p>
              <p>By rethinking metering, white balance, and tone mapping, we can take pictures in places too dark for humans to see clearly.</p>
            </td>
          </tr>
          
          <tr onmouseout="font_stop()" onmouseover="font_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='font_image'><img src='images/font_after.png'></div>
                <img src='images/font_before.png'>
              </div>
              <script type="text/javascript">
                function font_start() {
                  document.getElementById('font_image').style.opacity = "1";
                }

                function font_stop() {
                  document.getElementById('font_image').style.opacity = "0";
                }
                font_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/abs/1910.00748">
                <papertitle>A Deep Factorization of Style and Structure in Fonts</papertitle>
              </a>
              <br>
              <a href="http://www.cs.cmu.edu/~asrivats/">Nikita Srivatsan</a>,
              <strong>Jonathan T. Barron</strong>,
              <a href="https://people.eecs.berkeley.edu/~klein/">Dan Klein</a>,
              <a href="http://cseweb.ucsd.edu/~tberg/">Taylor Berg-Kirkpatrick</a>
              <br>
              <em>EMNLP</em>, 2019 &nbsp <font color="red"><strong>(Oral Presentation)</strong></font>
              <br>
              <p></p>
              <p>Variational auto-encoders can be used to disentangle a characters style from its content.</p>
            </td>
          </tr>
          
          <tr onmouseout="dpzlearn_stop()" onmouseover="dpzlearn_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='dpzlearn_image'><img src='images/dpzlearn_after.jpg'></div>
                <img src='images/dpzlearn_before.jpg'>
              </div>
              <script type="text/javascript">
                function dpzlearn_start() {
                  document.getElementById('dpzlearn_image').style.opacity = "1";
                }

                function dpzlearn_stop() {
                  document.getElementById('dpzlearn_image').style.opacity = "0";
                }
                dpzlearn_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/abs/1904.05822">
                <papertitle>Learning Single Camera Depth Estimation using Dual-Pixels</papertitle>
              </a>
              <br>
              <a href="http://rahuldotgarg.appspot.com/">Rahul Garg</a>,
              <a href="http://nealwadhwa.com">Neal Wadhwa</a>,
              <a href="">Sameer Ansari,</a>,
              <strong>Jonathan T. Barron</strong>
              <br>
              <em>ICCV</em>, 2019 &nbsp <font color="red"><strong>(Oral Presentation)</strong></font>
              <br>
              <a href="https://github.com/google-research/google-research/tree/master/dual_pixels">code</a> /
              <a href="data/GargICCV2019.bib">bibtex</a>
              <p></p>
              <p>Considering the optics of dual-pixel image sensors improves monocular depth estimation techniques.</p>
            </td>
          </tr>
          
          <tr onmouseout="porlight_stop()" onmouseover="porlight_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='porlight_image'><img src='images/porlight_after.jpg'></div>
                <img src='images/porlight_before.jpg'>
              </div>
              <script type="text/javascript">
                function porlight_start() {
                  document.getElementById('porlight_image').style.opacity = "1";
                }

                function porlight_stop() {
                  document.getElementById('porlight_image').style.opacity = "0";
                }
                porlight_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/abs/1905.00824">
                <papertitle>Single Image Portrait Relighting</papertitle>
              </a>
              <br>
              <a href="http://kevinkingo.com/">Tiancheng Sun</a>,
              <strong>Jonathan T. Barron</strong>,
              <a href="https://ai.google/research/people/105312/">Yun-Ta Tsai</a>,
              <a href="https://cseweb.ucsd.edu/~zex014/">Zexiang Xu</a>, Xueming Yu,
              <a href="http://ict.usc.edu/profile/graham-fyffe/">Graham Fyffe</a>, Christoph Rhemann, Jay Busch,
              <a href="https://www.pauldebevec.com/">Paul Debevec</a>,
              <a href="https://cseweb.ucsd.edu/~ravir/">Ravi Ramamoorthi</a>
              <br>
              <em>SIGGRAPH</em>, 2019
              <br>
              <a href="https://www.youtube.com/watch?v=yxhGWds_g4I">video</a> /
              <a href="https://petapixel.com/2019/07/16/researchers-developed-an-ai-that-can-relight-portraits-after-the-fact/">press</a> /
              <a href="data/SunSIGGRAPH2019.bib">bibtex</a>
              <br>
              <p></p>
              <p>Training a neural network on light stage scans and environment maps produces an effective relighting method.</p>
            </td>
          </tr>

          <tr onmouseout="loss_stop()" onmouseover="loss_start()" bgcolor="#ffffd0">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='loss_image'><img src='images/loss_after.png'></div>
                <img src='images/loss_before.png'>
              </div>
              <script type="text/javascript">
                function loss_start() {
                  document.getElementById('loss_image').style.opacity = "1";
                }

                function loss_stop() {
                  document.getElementById('loss_image').style.opacity = "0";
                }
                loss_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://drive.google.com/open?id=1xpZ0f
